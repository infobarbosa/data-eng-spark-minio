services:
  mysql:
    image: bitnami/mysql:latest
    environment:
      - MYSQL_ROOT_PASSWORD=my_password
      - MYSQL_DATABASE=metastore
    mem_limit: 512m
    networks:
      - spark_net
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "--host=localhost", "--password=my_password"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  hive-metastore:
    image: apache/hive:4.0.1
    container_name: hive-metastore
    environment:
      # Ajustar se necessário, pode-se definir HIVE_HOME se não estiver no PATH:
      # - HIVE_HOME=/opt/hive
      # Caso precise definir CLASSPATH para o conector MySQL, fazer aqui:
      - CLASSPATH=/opt/hive/lib/mysql-connector-java.jar:$CLASSPATH
    depends_on:
      mysql:
        condition: service_healthy
    mem_limit: 512m
    volumes:
      - ./hive-site.xml:/opt/hive/conf/hive-site.xml
      # Caso precise do driver MySQL, monte-o:
      - ./mysql-connector-j-9.1.0.jar:/opt/hive/lib/mysql-connector-java.jar
    command: >
      sh -c "
      schematool -dbType mysql -initSchema --verbose &&
      hive --service metastore
      "
    ports:
      - "9083:9083"
    networks:
      - spark_net
    healthcheck:
      # Verifica se a porta do metastore está aberta
      test: ["CMD", "nc", "-z", "localhost", "9083"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  minio:
    image: minio/minio:latest
    container_name: minio
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    command: server /data --console-address ":9090"
    ports:
      - "9000:9000"
      - "9090:9090"
    volumes:
      - ./data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    mem_limit: 512m
    networks:
      - spark_net

  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_NO_DAEMONIZE=true
      - SPARK_EVENTLOG_ENABLED=true
      - SPARK_EVENTLOG_DIR=file:///tmp/spark-events
      - SPARK_SQL_CATALOG_IMPLEMENTATION=hive
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./spark-events:/tmp/spark-events
      - ./hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml
    mem_limit: 512m
    networks:
      - spark_net
    depends_on:
      hive-metastore:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  spark-worker-1:
    image: bitnami/spark:latest
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=512m
      - SPARK_WORKER_CORES=1
      - SPARK_NO_DAEMONIZE=true
      - SPARK_SQL_CATALOG_IMPLEMENTATION=hive
    depends_on:
      spark-master:
        condition: service_healthy
    volumes:
      - ./hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml
    mem_limit: 512m
    networks:
      - spark_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  spark-worker-2:
    image: bitnami/spark:latest
    container_name: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=512m
      - SPARK_WORKER_CORES=1
      - SPARK_NO_DAEMONIZE=true
      - SPARK_SQL_CATALOG_IMPLEMENTATION=hive
    depends_on:
      spark-master:
        condition: service_healthy
    volumes:
      - ./hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml
    mem_limit: 512m
    networks:
      - spark_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  spark-history-server:
    image: bitnami/spark:latest
    container_name: spark-history-server
    environment:
      - SPARK_MODE=history-server
      - SPARK_HISTORY_SERVER_OPTS=--dir /tmp/spark-events
      - SPARK_NO_DAEMONIZE=true
      - SPARK_SQL_CATALOG_IMPLEMENTATION=hive
    depends_on:
      spark-master:
        condition: service_healthy
    volumes:
      - ./spark-events:/tmp/spark-events
      - ./hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml
    ports:
      - "18080:18080"
    mem_limit: 512m
    networks:
      - spark_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:18080"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

networks:
  spark_net:
    driver: bridge
